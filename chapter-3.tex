\documentclass[11pt, twocolumn]{report}
\usepackage{amssymb}
\usepackage{amsmath}
\usepackage[margin=0.75in]{geometry}

\begin{document}
\setcounter{chapter}{2}
\chapter{Probability and Information Theory}
Probability Theory
\begin{itemize}
  \item a mathematical framework for representing uncertain statements
  \item provides a means of quantifing uncertainty
  \item allows us to reason in the presence of uncertainty
  \item this is useful for AI systems because the laws of probability tell us
    how they should reason, also for analyzing their behavior
  \item was originally developed to analyze the frequencies of events
  \item defines a set of formal rules for determining the likelihood of a
    proposition being true given the likelihood of other propositions
\end{itemize}

Information Theory
\begin{itemize}
  \item allows us to quantify the amount of uncertainty in a probability
    distribution
\end{itemize}

\section{Why Probability?}
\begin{itemize}
  \item even though many branches of computer science deal mostly with entities
    that are deterministic/certain, machine learning ALWAYS deals with
    uncertain and sometimes stochastic quantities
  \item nearly all activities require some ability to reason amidst uncertainty
  \item in fact it is hard to think of examples beyond mathematical statements
    (that are true by definition) 
\end{itemize}

\textbf{(3)} possible sources of uncertainty:
\begin{enumerate}
  \item inherent stochasticity in the system being modeled
  \item incomplete observability (even deterministic systems can appear
    stochastic when we cannot observe all the variables the drive the system's
    behavior)
  \item incomplete modeling (when we use a model that must discard some of the
    information we have observed, the discarded information can result in
    uncertainty in the model's predictions)
\end{enumerate}

\textbf{Frequentist probability}:
\begin{itemize}
  \item related directly to the rates at which \textit{repeatable} events occur
  \item events like drawing a certain hand of cards in a poker game (repeatable)
\end{itemize}

\textbf{Bayesian probability}:
\begin{itemize}
  \item related to the qualitative levels of uncertainty (\textbf{degree of
      belief})
  \item like when a doctor says that a patient has a 40\% chance of having the
    flu (degree of belief = 40 percent)
\end{itemize}

It is proven that Bayesian probabilities are controlled by the same axioms as
the ones that govern Frequentist probabilities. (Ramsey, 1926)

\section{Random Variables}
\begin{itemize}
  \item a \textbf{random variable} is a variable that can take on different
    variables randomly
  \item typically denoted by a lowercase letter in plain typeface, and the
    values it can take on with lowercase script letters
  \item random variable x, with possible values $x_1$ and $x_2$
  \item on its own, it is merely a description of which states are possible 
  \item it must be coupled with a probability distribution that specifies how
    likely each of these states are
  \item may be discrete or continuous
  \item a discrete random variable is one that has finite or countably
    infinite states (not necessarily the integers, can also just be named
    states)
  \item a continuous random variable is associated with a real value
\end{itemize}

\section{Probability Distributions}
A \textbf{probability distribution} is a description of how likely a random
variable or a set of random variables is to take on each of its possible
states.

\subsection{Discrete Variables and Probability Mass Functions}
\begin{itemize}
  \item a probability distribution over discrete variables may be described
    using a \textbf{probability mass function} (PMF)
  \item we denote them with a capital $P$
  \item the PMF maps from a state of a random variable to the probability of
    the random variable taking on that state
  \item in other words, the probability that x = $x$ is $P(x)$, with a
    probability of 1 indicating that x = $x$ is certain and a probability of 0
    indicating that x = $x$ is impossible
  \item to disambiguate, sometime we write the name of the random variable
    inside the function's argument explicitly: $P(\text{x} = x)$
  \item states that a random variable x comes from a particular distribution: x
    $ \sim P(x)$
  \item joint PMFs act on many variables simultaneously: $P(\text{x} = x,
    \text{y} = y)$, can also be written as $P(x, y)$ for brevity
\end{itemize}
\textbf{(3)} properties for a function $P$ to be a PMF:
\begin{enumerate}
  \item The domain of $P$ must be the set of all possible values of x.
  \item $\forall x \in \text{x}, 0 \leq P(x) \leq 1$. 
  \item $\sum_{x \in \text{x}} P(x) = 1$. We refer to this property as being
    \textbf{normalized}.
\end{enumerate}

\subsection{Continuous Variables and Probability Density Functions}
A \textbf{probability density function} (PDF) is needed when continuous random
varibles are involved rather than a PMF. 

\textbf{(3)} properties for a function $p$ to be a PDF:
\begin{enumerate}
  \item The domain of $p$ must be the set of all possible states of x.
  \item $\forall x \in \text{x}, p(x) \geq 0$. Note that we do not require
    $p(x) \leq 1$.
  \item $\int_{-\infty}^{\infty} p(x)dx = 1$.
\end{enumerate}

Note that a PDF $p(x)$ does not give the probability of a particular state
directly; instead it gives the probability of landing in an infinitesimal
region with volume $\delta x$ is given by $p(x)\delta x$.

The probability that $x$ lies in the interval $[a, b]$ is given by $\int_{[a,
  b]} p(x)dx$.

\section{Marginal Probability}
\begin{itemize}
  \item used when we know the probability distribution across a set of
    variables and we want to know the probability distribution over just a
    subset of them
  \item the probability distribution over the subset is known as the
    \textbf{marginal probability distribution}
  \item discrete variables (derived by the \textbf{sum rule}:
    \begin{equation}
      \forall x \in \text{x}, P(\text{x} = x) = \sum_y P(\text{x} = x, \text{y}
      = y)
    \end{equation}
  \item continuous variables:
    \begin{equation}
      p(x) = \int p(x, y)dy
    \end{equation}
\end{itemize}

\section{Conditional Probability}
\begin{itemize}
  \item the probability of some event, given that some other event has happened
  \item known as the \textbf{conditional probability}
  \item $P(\text{y} = y \text{ } | \text{ x} = x)$
  \item the conditional probability y = $y$ given x = $x$
  \item and is given by the formula:
    \begin{equation}
      P(\text{y} = y \text{ } | \text{ x} = x) = 
      \frac{P(\text{y} = y, \text{x} = x)}{P(\text{x} = x)}
    \end{equation}
  \item the numerator of the above formula is the \textit{joint probability} of
    A and B
  \item the conditional probability is only defined when $P(\text{x} = x) > 0$
  \item because we cannot compute the conditional probability hinged on an
    event that never occurs
\end{itemize}

\section{The Chain Rule of Conditional Probabilities}
Any joint probability distribution over $n$ random variables may be decomposed
into conditional distributions over only one variable:
\begin{equation}
  P(\text{x}^{(1)},...,\text{x}^{(n)}) = P(\text{x}^{(1)} \prod_{i = 2}^{n}
  P(\text{x}^{(i)} \text{ } | \text{ } \text{x}^{(1)},..., \text{x}^{(i-1)})
\end{equation}
This is called the \textbf{chain rule} or the \textbf{product rule} of
probability.\\
Given this, $P(a, b, c) = P(a | b,c)P(b|c)P(c)$.

\section{Independence and Conditional Independence}


\end{document}
