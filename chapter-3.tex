\documentclass[11pt, twocolumn]{report}
\usepackage{amssymb}
\usepackage{amsmath}
\usepackage[margin=0.75in]{geometry}

\begin{document}
\setcounter{chapter}{2}
\chapter{Probability and Information Theory}
Probability Theory
\begin{itemize}
  \item a mathematical framework for representing uncertain statements
  \item provides a means of quantifing uncertainty
  \item allows us to reason in the presence of uncertainty
  \item this is useful for AI systems because the laws of probability tell us
    how they should reason, also for analyzing their behavior
  \item was originally developed to analyze the frequencies of events
  \item defines a set of formal rules for determining the likelihood of a
    proposition being true given the likelihood of other propositions
\end{itemize}

Information Theory
\begin{itemize}
  \item allows us to quantify the amount of uncertainty in a probability
    distribution
\end{itemize}

\section{Why Probability?}
\begin{itemize}
  \item even though many branches of computer science deal mostly with entities
    that are deterministic/certain, machine learning ALWAYS deals with
    uncertain and sometimes stochastic quantities
  \item nearly all activities require some ability to reason amidst uncertainty
  \item in fact it is hard to think of examples beyond mathematical statements
    (that are true by definition) 
\end{itemize}

\textbf{3} possible sources of uncertainty:
\begin{enumerate}
  \item inherent stochasticity in the system being modeled
  \item incomplete observability (even deterministic systems can appear
    stochastic when we cannot observe all the variables the drive the system's
    behavior)
  \item incomplete modeling (when we use a model that must discard some of the
    information we have observed, the discarded information can result in
    uncertainty in the model's predictions)
\end{enumerate}

\textbf{Frequentist probability}:
\begin{itemize}
  \item related directly to the rates at which \textit{repeatable} events occur
  \item events like drawing a certain hand of cards in a poker game (repeatable)
\end{itemize}

\textbf{Bayesian probability}:
\begin{itemize}
  \item related to the qualitative levels of uncertainty (\textbf{degree of
      belief})
  \item like when a doctor says that a patient has a 40\% chance of having the
    flu (degree of belief = 40 percent)
\end{itemize}

It is proven that Bayesian probabilities are controlled by the same axioms as
the ones that govern Frequentist probabilities. (Ramsey, 1926)

\section{Random Variables}
\begin{itemize}
  \item a \textbf{random variable} is a variable that can take on different
    variables randomly
  \item typically denoted by a lowercase letter in plain typeface, and the
    values it can take on with lowercase script letters
  \item random variable x, with possible values $x_1$ and $x_2$
  \item on its own, it is merely a description of which states are possible 
  \item it must be coupled with a probability distribution that specifies how
    likely each of these states are
  \item may be discrete or continuous
  \item a discrete random variable is one that has finite or countably
    infinite states (not necessarily the integers, can also just be named
    states)
  \item a continuous random variable is associated with a real value
\end{itemize}

\section{Probability Distributions}
A \textbf{probability distribution} is a description of how likely a random
variable or a set of random variables is to take on each of its possible
states.

\subsection{Discrete Variables and Probability Mass Functions}
\begin{itemize}
  \item a probability distribution over discrete variables may be described
    using a \textbf{probability mass function} (PMF)
  \item we denote them with a capital $P$
  \item the PMF maps from a state of a random variable to the probability of
    the random variable taking on that state
  \item in other words, the probability that x = $x$ is $P(x)$, with a
    probability of 1 indicating that x = $x$ is certain and a probability of 0
    indicating that x = $x$ is impossible
  \item to disambiguate, sometime we write the name of the random variable
    inside the function's argument explicitly: $P(\text{x} = x)$
  \item states that a random variable x comes from a particular distribution: x
    $ \sim P(x)$
  \item joint PMFs act on many variables simultaneously: $P(\text{x} = x,
    \text{y} = y)$, can also be written as $P(x, y)$ for brevity
\end{itemize}
\textbf{(3)} properties for a function to be a PMF:
\begin{enumerate}
  \item The domain of $P$ must be the set of all possible values of x.
  \item $\forall x \in \text{x}, 0 \leq P(x) \leq 1$. 
  \item $\sum_{x \in \text{x}} P(x) = 1$. We refer to this property as being
    \textbf{normalized}.
\end{enumerate}

\end{document}
