\documentclass[11pt, twocolumn]{report}
\usepackage[margin=0.75in]{geometry}
\usepackage{amssymb}
\usepackage{amsmath}
\usepackage{bm}
\def\realnumbers{\mathbb{R}}

\begin{document}
\setcounter{chapter}{4}
\chapter{Machine Learning Basics}

Overview:
\begin{itemize}
  \item what is a learning algorithm?
  \item fitting training data (to a model) is a different beast altogether from
    finding new patterns that generalize to new data
  \item for more reading, read Murphy (2012) or Bishop (2006)
  \item most ML algorithms have settings called \textit{hyperparameters}
  \item \textbf{machine learning is essentially a form of applied statistics
      with an increased emphasis on the use of computers to statistically
      estimate complicated functions and a decreased emphasis on proving
      confidence intervals around these functions}
  \item frequentist estimators and Bayseian inference
  \item supervised vs unsupervised learning
  \item most ML algorithms are based on an optimization algorithm called
    \textbf{stochastic gradient descent}
  \item the main components for an ML algorithm are: an optimization algorithm,
    a cost function, a model, a dataset
  \item factors that limit the ability of traditional machine learning to
    generalize
\end{itemize}

\section{Learning Algorithms}
A machine learning algorithm is an algorithm that is able to learn from data.
But what do we mean by \textit{learning}? Mitchell (1997) provides a succinct
definition:

"A computer program is said to learn from experience $E$ with
respect to some class of tasks $T$ and performance measure $P$, if its
performance at tasks in $T$ (as measured by $P$) improves with experience $E$."

\subsection{The Task, $T$}
\begin{itemize}
  \item the process of learning itself is \textbf{not} the task
  \item learning is the means of attaining the ability to perform the task
  \item if we want a robot to walk, then walking is the task
  \item machine learning tasks are usually describe in terms of how the machine
    learning system should process an \textbf{example}
  \item an example is a collection of \textbf{features} that have been
    quantitatively measured from some object or event that we want the machine
    learning to process
  \item we typically represent an example as a vector $\bm{x} \in
    \realnumbers^n$ where each entry $x_i$ of the vector is another feature
  \item the features of an image are usually the value of the pixels in the
    image
  \item there are many kinds of tasks that can be solved with machine
    learning
\end{itemize}

\subsubsection{Examples of tasks}

\underline{Classification}
\begin{itemize}
  \item specify which of $k$ categories some input belongs to
  \item we ask the system to produce some function $f : \realnumbers^n \to
    \{1,...,k\}$
  \item when $y = f(\bm{x})$, assigns an input described by vector $\bm{x}$ to
    a category identified by numeric code $y$ to a category identified by
    numeric code $y$
  \item an example is an input image, and the output is a numeric code
    identifying the object in the image
  \item object recognition is the same basic tech as facial recognition
\end{itemize}

\underline{Regression}
\begin{itemize}
  \item predict a numerical value given some input
  \item $f : \realnumbers^n \to \realnumbers$
  \item similar to classification save for the output (categorical vs numeric)
  \item an example is the prediction of future prices of produce
  \item these kinds of predictions are used for algorithmic trading
\end{itemize}

\underline{Transcription}
\begin{itemize}
  \item observe a relatively unstructured representaion of some kind of data
    and transcribe the information into discrete textual form
  \item optical character recognition
  \item image of text (.jpeg, .gif) to strings (e.g., in ASCII or Unicode)
  \item Google Street View uses deep learning to process address numbers in
    this way
  \item speech recognition, audio waveform to a sequence of characters 
\end{itemize}

\underline{Machine Translation}
\begin{itemize}
  \item input: sequence of symbols in some language
  \item output: sequence of symbols in another language
  \item commonly applied to natural languages, such as translating from English
    to French
\end{itemize}

\underline{Structured Output}
\begin{itemize}
  \item refers to the tasks where the output is a vector (or any data structure
    containing multiple values) with important relationships between the
    different elements
  \item one example is parsing -- mapping a natural language sentence into a
    tree that describes its grammatical structure by tagging its nodes as beig
    verbs, nouns, adverbs, and so on
  \item image captioning
\end{itemize}

\underline{Anomaly Detection}
\begin{itemize}
  \item sifts through a set of events or objects and flags some of them as
    being unusual or atypical
  \item an example is credit card fraud detection
  \item by modeling one's purchasing habits, a credit card company can detect
    misuse of your cards
  \item the thief's purchases will often come from a different probability
    distribution over purchase types than your own
\end{itemize}

\underline{Synthesis and Sampling}
\begin{itemize}
  \item generate new examples that are similar to those in the training data
  \item useful for media applications where generating large volumes of content
    by hand would be expensive, boring, or require too much time
  \item examples include texture generation for video games
  \item speech synthesis - written sentence $\to$ audio waveform containing the
    spoken version of said sentence
  \item we explicitly desire a large amount of variation in the output in order
    for it to seem more natural
\end{itemize}

\underline{Imputation of missing values}
\begin{itemize}
  \item the algorithm is given a new example $\bm{x} \in \realnumbers^n$, but
    with some entries $x_i$ of $\bm{x}$ missing
  \item the algorithm then must provide a prediction of the values of the
    missing entries\\\\\\
\end{itemize} 

\underline{Denoising}
\begin{itemize}
  \item the algorithm is given a \textit{corrupted example} $\widetilde{\bm{x}}
    \in \realnumbers^n$ obtained by an unknown corruption process from a
    \textit{clean example} $\bm{x} \in \realnumbers^n$
  \item the learner must predict the clean example from its corrupted version 
  \item more generally, predict the probability distribution $p(\bm{x} |
    \widetilde{\bm{x}})$
\end{itemize}

\underline{Density estimation}
\begin{itemize}
  \item the algorithm is asked to learn a function $p_{model} : \realnumbers^n
    \to \realnumbers$, where $p_{model}(\bm{x})$ can be interpreted as a pdf or
    pmf depending on the nature of $\bm{x}$ (continuous vs discrete)
  \item basically allows us to capture what distribution the examples were
    drawn from
  \item the algorithm needs to learn the structure of the training data
  \item after getting the pdf/pmf, a lot of othe tasks can be solved as well
    (like value imputation)
  \item in practice though, density estimation does not always enable us to
    solve all related tasks, because in many cases operations on $p(\bm{x})$
    are computationally intractable
\end{itemize}

There are many other types of tasks that are not mentioned, this is just to
give you a general idea of what is possible with machine learning.

\subsection{The Performance Measure, $P$}
\begin{itemize}
  \item usually, $P$ is speciic to task $T$
  \item \textbf{accuracy} - the proportion of examples for which the model
    produces the 'correct' output
  \item \textbf{error rate} - the proportin of examples for which the model
    produces the 'wrong' output
  \item the error rate is also known as the expected \textbf{0-1 loss} (0 if
    correctly classified and 1 if it is not)
  \item there are other tasks like density estimation where it does not make
    sense to measure accuracy, instead we use a metric that gives the model a
    real-valued score
  \item we get these performance metrics using the \textbf{test set} of data
  \item this test set is separate from the \textbf{training set}
  \item in some cases it is difficult to quantify performance metrics
  \item in a transcription task, should accuracy be aimed at trancscribing
    entire sequences or should a more fine-grained approach be used, as in
    partial credits for getting some of the elements correctly?
  \item in a regression task, should we penalize a system more for making
    frequent medium-sized mistakes or if it rarely makes very large mistakes?
  \item these kind of design choices largely depend on the application of the
    system
  \item in other cases measuring it is impractical even
\end{itemize}

\subsection{The Experience, $E$}
Machine learning algorithms can be broadly categorized as \textbf{unsupervised}
or \textbf{supervised} by what kind of experience they are allowed to have
during the learning process.

Most of what learning algorithms in this book can be understood as being
allowed to experience an entire \textbf{dataset}. A dataset is a collection of
many examples. Sometimes examples are known as data points.

Example: The Iris Dataset
\begin{itemize}
  \item a collection of measurements of different parts of 150 iris plants
  \item each individual plant = one example
  \item there are features within each example: things like sepal length, sepal
    width, petal length, and petal height
  \item the dataset also records which species each plant belongs to (there are
    three species)
\end{itemize}

\subsubsection{Unsupervised learning algorithms}
\begin{itemize}
  \item they experience a dataset containing many features
  \item then they themselves learn useful properties of the structure of this
    dataset a la inference
  \item we usually want to learn the entire probability distribution that
    generated the dataset
\end{itemize}

\subsubsection{Supervised learning algorithms}
\begin{itemize}
  \item same as unsupervised but each example is also associated with a
    \textbf{label}
  \item the Iris dataset is annotated with the species of each iris plant
  \item a supervised learning algorithm can study the Iris dataset and learn to
    classify iris plants into three different species based on their
    measurements and whatnot
\end{itemize}

\subsubsection{Supervised vs Unsupervised}
\begin{itemize}
  \item roughly speaking, unsupervised learning involves observing several
    examples of a random vector $\bm{x}$ and attempting to learn the probability
    distribution $p(\bm{x})$
  \item supervised learning involves observing several examples of a random
    vector $\bm{x}$ and an associated value or vector $\bm{y}$, then learning
    to predict $\bm{y}$ from $\bm{x}$, usually by estimating $p(\bm{y} |
    \bm{x})$
  \item the term 'supervised' comes from an instructor (you) 'showing' (giving
    examples $\bm{y}$) the student (the machine learning system) what to do
  \item in unsupervised learning you don't show the system what to do, it'll
    automagically try to infer stuff based from the dataset
  \item supervised learning is tedious because you have to individually label
    each example, which might be costly
  \item they aren't formally defined terms though
  \item traditionaly, people refer to \textbf{regression, classification, and
      structured output problems} as supervised learning
  \item \textbf{density estimation} in support of other tasks is unsupervised
    learning
\end{itemize}

\subsubsection{Other variants of learning}
\begin{itemize}
  \item there are other variants such as
  \item semi-supervised learning - some are labeled, some are not
  \item multi-instance learning - the entire collection is labeled or not
    containg an example of a clss, but the individual members aren't labeled
  \item reinforcement leaning - there is a feedback loop between the learning
    system and its experiences; you reward the system for producing the correct
    output and punish it for the wrong output
\end{itemize}

\subsubsection{The Dataset}
\begin{itemize}
  \item datasets are a collection of examples -> examples are a collection of
    features
  \item one common way to describe a dataset is with a \textbf{design matrix}
  \item a design matrix is a matrix containing a different example each row
  \item for instance, the Iris dataset contains 150 examples with 4 features
    for each example
  \item so we can represent these information as a design matrix $\bm{X} \in
    \realnumbers^{150 \times 4}$, where $X_{i, 1}$ is the sepal length, and so
    on
  \item most of the learning algorithms in this book operate on design matrices
  \item it is not always possible for the sub-vectors (each row) of the matrix
    to be of the same size
  \item in that case rather than describing the dataset as a matrix with $m$
    rows, we describe it a s a set containing $m$ elements:
    ${\bm{x}^{(1)},...\bm{x}^{(m)}}$
  \item this notation does not imply that any two example vectors within the
    set have the same size
  \item for labels in supervised learning, it can be anything: numeric codes,
    for categories, or strings, etc
  \item there is no rigid taxonomy for datasets and experiences, so one can be
    creative with how they are represented so long as it works well
\end{itemize}

\subsection{Example: Linear Regression}
\begin{itemize}
  \item an ML algorithm is an algorithm that is capable of improving a
    computer's performance at some task via experience
  \item to make this more concrete, let us examine \textbf{linear regression}
  \item as it name implies, it is a regression task
  \item to goal is to build a system thas has a function $f : \bm{x} \in
    \realnumbers^n \to y \in \realnumbers$
  \item the output of the linear regression is a linear function of the input
  \item we define the output to be:
    \begin{equation}
      \hat{y} = \bm{w}^\intercal\bm{x},
    \end{equation}
    where $\hat{y}$ is the predicted value, and $\bm{w} \in \realnumbers^n$ is
    a vector of \textbf{parameters}
  \item parameters are values that control the behavior of the system
  \item $\bm{w}$ is the coefficient matrix, and we can think of it as a set of
    \textbf{weights} that determine how much each feature affects the final
    prediction
  \item if a feature's weight has a large magnitude, that means it has a large
    effect on the prediction
  \item thus we have a definition for task $T$: predict $y$ from $\bm{x}$ by
    outputting $\hat{y} = \bm{w}^\intercal\bm{x}$
  \item one way of measuring linear regression is to computer the \textbf{mean
      squared error} of the model on the test set:
    \begin{equation}
      \text{MSE}_{\text{test}} = \frac{1}{m} \sum_i ( \hat{\bm{y}}^{(test)} -
      \bm{y}^{(test)})_i^2
    \end{equation}
  \item this error measure decreases to zero when $\hat{\bm{y}}^{(test)} =
    \bm{y}^{(test)}$
  \item so to minimize MSE, we can simply solve for where its gradient is
    $\bm{0}$:
    \begin{equation}
      \label{parameter_solution}
      \Rightarrow \bm{w} = \left(\bm{X}^{(train)\intercal}
        \bm{X}^{(train)}\right)^{-1} \bm{X}^{(train)} \bm{y}^{(train)}
    \end{equation}
  \item evaluation equation \ref{parameter_solution} constitutes a simple
    learning algorithm
  \item it is worth noting that linear regression has another parameter $b$
    (the constant) such that the mapping from features to predictions is now an
    \textbf{affine function}:
    \begin{equation}
      \hat{y} = \bm{w}^\intercal\bm{x} + b
    \end{equation}
  \item *an affine function is one that translates the whole graph by
    coordinate $a$, a linear transformation followed by translation
  \item the intercept term $b$ is often called the \textbf{bias} parameter
  \item this terminology comes from when the output tends to go to $b$ in the
    absence of any input, different from a \textbf{statistical bias}
\end{itemize}

\section{Capacity, Overfitting, and Underfitting}
The central challenge in any learning algorithm is that it must perform well on
\textit{new, previously unseen} inputs -- not only those in the training set.
The ability to perform well on previously unobserved input is known as
\textbf{generalization}.
Some terms:
\begin{itemize}
  \item training error - an error measure on the training set
  \item generalization/test error - expected value of the error on a new input
  \item generalization error is measured on a \textbf{test set}
  \item the question is: how can we affect performance on the test set when we
    can observe only the training set?
\end{itemize}

\subsubsection{Statistical learning theory}
\begin{itemize}
  \item we typically make a set of assumptions known collectively as
    \textbf{i.i.d}
  \item i.i.d = examples are independent (the probabilty that one event occurs
    in no way affects the probability of another event occuring) and
    identically distributed (drawn from the same probability distribution)
  \item assume that the distribution for the training set and test set is the
    same based from a single example
  \item we call this shared underlying distribution the \textbf{data-generating
      distribution}, denoted $p_{data}$
  \item collectively, these allow us to mathematically study the relationship
    between training set and test set (and their errors)
  \item so we can definitely assume that expected training error = expected
    test error
  \item procedure: sample the training set $\to$ use it to choose parameters to
    reduce training set error $\to$ sample the test set
  \item under this process, $\mathbb{E}[error_{test}] \geq
    \mathbb{E}[error_{training}]$
  \item for a machine learning algorithm to perform well, it has to: a)
    \textit{make the training error as small as possible}, and b) \textit{make
      the gap between training error and test error as small as possible}
  \item these two factors correspond to two central challenges in machine
    learning: \textbf{overfitting}, and \textbf{underfitting}
  \item underfitting: the model is not able to obtain a sufficiently low error
    on the training set
  \item overfitting: the gap between training and test error is too large
  \item capacity: the ability to fit a wide variety of mathematical functions
  \item models with low capacity may struggle to fit the training set
  \item models with high capacity can overfit by memorizing properties of the
    training set that do not serve them well on the test set
  \item conrolling capacity: choose a proper \textbf{hypothesis space}
  \item hypothesis space: the set of functions that the learning algorithm is
    allowed to select as its solution
  \item the linear regression algorithm has the set of all linear functions in
    its hypothesis space
  \item including other polynomials in its hypothesis space increases the
    model's capacity    
  \item this is fine because the output is still a linear function of its
    \textit{parameters}, even though the input may have quadratics or cubics et
    al
  \item ML algorithms generally perform the best when their capacity is
    appropriate for the true complexity of the task and the amount of training
    data they are provided with
  \item so a way to change capacity is by changing the number of input features
    it has, and simultaneously adding new parameters associated with those
    features
  \item \textbf{representational capacity} - the family of functions the
    learning algorithm can choose from when varying the parameters 
  \item \textbf{Occam's razor} - among competing hypotheses that explain known
    observations equally well, we should choose the "simplest" one
  \item statistical learning theory provides various means of quantifying model
    capacity
  \item the most well known is the \textbf{Vapnik-Chervonenkis dimension} or VC
    dimension
  \item VC dimension measures the capacity of a binary classifier
  \item VC dimension is defined as being the largest possible value of $m$ for
    which there exists a training set of $m$ different $\bm{x}$ points that the
    classifier can label arbitrarily
  \item the most important results in statistical learning theory shows that
    \textbf{the discrepancy between training error and generalization error is
      bounded from above by a quantity that grows as the model capacity grows
      but shrinks as the number of training examles increases}
  \item in my own terms, this means that the higher you make a model's
    capacity, after a certain point (the optimal capacity), it won't be able to
    generalize well (will have a high test error) (but of course, its training
    error will be super low)
  \item to balance it all out, we need to choose a sufficiently complex
    hypothesis to achieve low training/test error
  \item nonparametric learning algorithms are used to reach arbitrarily high
    capacity
  \item sometimes, they are just theoretical absractions that cannot be
    implemented in practice
  \item we can make a nonparametric learning algorithm by wrapping a parametric
    learning algorithm inside another algorithm that increases the number of
    parameters as needed
  \item \textbf{Bayes error rate} - the lowest possible error rate for any
    classifier of a random outcome (for instance, one of two categories) and is
    analogous to the irreducible error
  \item expected generalization \textbf{can never increase} as the number of
    training examples increases
  \item the more the merrier, even more so in machine learning, no exceptions
  \item any fixed parametric model with less then optimal capacity \textbf{will
      asymptote to an error value that exceed the Bayes error}
  \item the main takeaway in the above wall of text is that \textbf{capacity is
      very different from training set size, do not see them as the same thing}
\end{itemize}

\subsection{The No Free Lunch Theorem}
\begin{itemize}
  \item machine learning promises the find rules that are \textit{probably}
    correct about \textit{most} members of the set they are concerned about
  \item solutions aren't absolutes 
  \item because to logically infer a rule describing every member of a set, one
    must have information about every member of that set (which is not possible
    most times)
  \item the \textbf{no free lunch theorem} for machine learning states that,
    averaged over all possible data-generating distributions, every
    classification algorithm has the same error rate when classifying prevously
    unobserved points
  \item this nihlistic theorem states that, in some sense, no machine learning
    algorithm is universally any better than any other
  \item fortunately, these theorem only holds when we average over \textit{all}
    possible data-generating distributions
  \item if we make assumptions about the probability distributions we enconter
    in real-world applications, we can design learning algorithms that perform
    well on these distributions
  \item indeed, the goal of ML research is to understand what kinds of
    distributions are relevant to the "real world", and what kinds of ML
    algorithms perform well on data drawn from these distributions
\end{itemize}

\subsection{Regularization}
\begin{itemize}
  \item we can design learning algorithms that perform well on a specific task
    via building a set of preferences into the learning algorithm
  \item we can control the performance of our algorithms by choosing what kind
    of functions we allow them to operate on, in addition to controlling the
    amount of these functions
  \item we can also give a learning algorithm a preference for one solution
    over another in its hypothesis space
  \item recall that including/excluding members from the hypotheses space
    controls a model's capacity
  \item expressing preference for one function over another is a generalization
    of this
  \item excluding functions: expressing an infinitely strong preference against
    that function
  \item we can \textbf{regularize} a model that learns a function
    $f(\bm{x};\bm{\Theta})$ by adding a penalty called a \textbf{regularizer}
    to the cost function
  \item \textit{regularization is any modification made to a learning algorithm
      that is intended to reduce its generalization error but not its training
      error}
  \item look up: \textbf{weight decay} for linear regresson
  \item one of the central concerns of the field of machine learning, next to
    optimization
  \item there is no best form of regularization, as implied by the no free
    lunch theorem
  \item again we choose a form of regularization that is well-suited to the
    task we wish to solve
  \item but a wide range of tasks may all be solved efficiently using very
    general-purpose forms of regularization
\end{itemize}

\section{Hyperparameters and Validation Sets}
\textbf{Hyperparameters}
\begin{itemize}
  \item most ML algorithms have them
  \item they cannot be directly learned from the regular training process
  \item they are settings we can use to control the algorithm's behavior
  \item "higher-level properties" -- complexity, how fast it should learn
  \item usually fixed before the actual training begins
  \item though we can design a nested learning algorithm in which one learns
    the best hyperparameters for another leaning algorithm
  \item in the case of polynomial regression: the degree of the polynomial, and
    the $\lambda$ value used to control the strength of weight decay
  \item linear-poly regression: "we can always fit the training set better with
    a higher-degree polynomial and a weight decay setting of $\lambda = 0$ than
    we could with a lower-degree polynomial with a positive weight decay
    setting
\end{itemize}
\textbf{Validation Set}
\begin{itemize}
  \item minimizes overfitting
  \item "trains" the hyperparameters
  \item composed of examples coming from the same distribution as the training
    set
  \item we split the data set into two disjoint subsets
  \item one of these subsets is for the model to learn the parameters (training
    set)
  \item the other is to minimize overfitting (validation set)
  \item typically we use 80\% of the data for training and 20\% for validation
    (assuming you don't have test cases)
\end{itemize}

\section{Estimators, Bias and Variance}
There are many foundational concepts such as parameter estimation, bias, and
variance that are useful to formally characterize notions of generalization,
underfitting, and overfitting.


\section{End-of-Chapter Summary and Miscellany}
\begin{itemize}
  \item model - a mathematical formula with a number of parameters that need to
    be learned from the training data, that also need to apply to future,
    unseen data
  \item the crux of machine learning: \textbf{fitting a model to the data}
  \item the bigger the dataset, the better. this always applies
  \item there is no hard and fast rule for "bigger" but strive to get something
    in the ballpark of thousands, tens of thousands, to millions
  \item rule of thumb: 70\% should be training cases, 10\% test cases, and 20\%
    validation cases
  \item in the context of deep learning:
  \item training set: the data used to adjust the weights on a neural network
  \item validation set: minimizes overfitting
  \item testing set: data used only for testing the final solution in order to
    confirm the actual predictive power of the network
  \item validation sets
\end{itemize}
\end{document}
